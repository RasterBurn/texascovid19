{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from texascovid19 import constants\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=\"https://gis.wilco.org/arcgis/rest/services/wcchd/Williamson_County_Cases/FeatureServer/0/query?f=json&where=Number_of_Cases%3E0&returnGeometry=false&spatialRel=esriSpatialRelIntersects&outFields=*&groupByFieldsForStatistics=City_of_Residence&outStatistics=%5B%7B%22statisticType%22%3A%22sum%22%2C%22onStatisticField%22%3A%22Number_of_Cases%22%2C%22outStatisticFieldName%22%3A%22value%22%7D%5D&outSR=102100\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x==constants.WILCO_CITY_XHR_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_html(constants.WILCO_URL, match=\"Summary of COVID\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_separator_rows(df):\n",
    "    \"\"\"The HTML table has an empty row to separate logical tables.  Get the indices of those\"\"\"\n",
    "    it = df.iterrows()\n",
    "    # skip to \"Summary\" row\n",
    "    for idx, row in it:\n",
    "        if not row.isna().all() and row[0].startswith(\"Summary of COVID\"):\n",
    "            _, header_row = next(it)\n",
    "            yield (idx+2, header_row[0])\n",
    "            break\n",
    "\n",
    "    # now look for separator rows of all NaNs\n",
    "    for idx, row in it:\n",
    "        if row.isna().all():\n",
    "            _, header_row = next(it)\n",
    "            \n",
    "            yield (idx+2, header_row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_separator_rows(df):\n",
    "    \"\"\"The HTML table has an empty row to separate logical tables.  Get the indices of those\"\"\"\n",
    "    it = df.iterrows()\n",
    "    # skip to \"Summary\" row\n",
    "    for idx, row in it:\n",
    "        if not row.isna().all() and row[0].startswith(\"Summary of COVID\"):\n",
    "            start_idx = idx + 2\n",
    "            _, header_row = next(it)\n",
    "            break\n",
    "\n",
    "    # now look for separator rows of all NaNs\n",
    "    for idx, row in it:\n",
    "        if row.isna().all():\n",
    "            yield (start_idx, idx, header_row[0])\n",
    "            start_idx = idx + 2\n",
    "            _, header_row = next(it)\n",
    "    yield (start_idx, idx, header_row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subtables(df):\n",
    "    common_headers = ['Number of Cases', '% of Total Cases']\n",
    "    for start_idx, end_idx, categ in find_separator_rows(df):\n",
    "        subdf = df.copy().iloc[start_idx:end_idx]\n",
    "        subdf.columns = [categ] + common_headers\n",
    "        yield subdf.set_index(categ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtables = list(generate_subtables(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_data = subtables[0]\n",
    "gender_data = subtables[1]\n",
    "age_data = subtables[2]\n",
    "status_data = subtables[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today().isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_data.to_csv(f\"{constants.DATA_PATH}/wilco/bycity/{today}.csv\", header=True, index=True)\n",
    "gender_data.to_csv(f\"{constants.DATA_PATH}/wilco/bygender/{today}.csv\", header=True, index=True)\n",
    "age_data.to_csv(f\"{constants.DATA_PATH}/wilco/byage/{today}.csv\", header=True, index=True)\n",
    "status_data.to_csv(f\"{constants.DATA_PATH}/wilco/bystatus/{today}.csv\", header=True, index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append today's data to timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORTS = [\n",
    "    (\"City of Residence\", \"bycity\", city_data),\n",
    "    (\"Gender\", \"bygender\", gender_data),\n",
    "    (\"Age Group\", \"byage\", age_data),\n",
    "    (\"Status\", \"bystatus\", status_data)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "for report in REPORTS:\n",
    "    df_timeseries = pd.read_csv(f\"{constants.DATA_PATH}/wilco/{report[1]}/timeseries.csv\").set_index(report[0])\n",
    "    df = report[2][[\"Number of Cases\"]].rename(columns={\"Number of Cases\": today})\n",
    "    if today in df_timeseries.columns:\n",
    "        df_timeseries.drop(columns=today, inplace=True)\n",
    "    df_timeseries = pd.concat([df_timeseries, df], axis=1).rename_axis(report[0])\n",
    "    df_timeseries = df_timeseries.fillna(0).convert_dtypes(convert_integer=True)\n",
    "    df_timeseries.to_csv(f\"{constants.DATA_PATH}/wilco/{report[1]}/timeseries.csv\", header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
